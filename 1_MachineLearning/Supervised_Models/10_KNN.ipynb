{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Number of training data samples-----> 10\n",
      "Number of training features --------> 20\n",
      "Shape of the target value ----------> (10, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define the traning data.\n",
    "X, y = make_classification(n_samples=10, n_classes=2)\n",
    "\n",
    "# Chnage the shape of the target to 1 dimentional array.\n",
    "y = y[:, np.newaxis]\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"Number of training data samples-----> {}\".format(X.shape[0]))\n",
    "print(\"Number of training features --------> {}\".format(X.shape[1]))\n",
    "print(\"Shape of the target value ----------> {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.217474</td>\n",
       "      <td>-1.379587</td>\n",
       "      <td>1.944832</td>\n",
       "      <td>-0.059574</td>\n",
       "      <td>-0.049941</td>\n",
       "      <td>0.669516</td>\n",
       "      <td>1.193189</td>\n",
       "      <td>-1.352304</td>\n",
       "      <td>0.084476</td>\n",
       "      <td>-0.242834</td>\n",
       "      <td>0.582384</td>\n",
       "      <td>1.564447</td>\n",
       "      <td>1.181442</td>\n",
       "      <td>1.565118</td>\n",
       "      <td>1.101566</td>\n",
       "      <td>-0.758229</td>\n",
       "      <td>-1.908754</td>\n",
       "      <td>1.038696</td>\n",
       "      <td>0.662362</td>\n",
       "      <td>-1.855495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.156258</td>\n",
       "      <td>-0.305180</td>\n",
       "      <td>-0.427243</td>\n",
       "      <td>0.658212</td>\n",
       "      <td>-1.824687</td>\n",
       "      <td>-0.196299</td>\n",
       "      <td>-0.528474</td>\n",
       "      <td>1.907793</td>\n",
       "      <td>0.718183</td>\n",
       "      <td>1.153174</td>\n",
       "      <td>-1.601738</td>\n",
       "      <td>0.149368</td>\n",
       "      <td>3.041237</td>\n",
       "      <td>0.525575</td>\n",
       "      <td>1.661824</td>\n",
       "      <td>0.566986</td>\n",
       "      <td>-0.136337</td>\n",
       "      <td>-1.539961</td>\n",
       "      <td>-0.535194</td>\n",
       "      <td>-1.642228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.167395</td>\n",
       "      <td>1.277966</td>\n",
       "      <td>0.867153</td>\n",
       "      <td>-2.152296</td>\n",
       "      <td>-0.333534</td>\n",
       "      <td>0.121870</td>\n",
       "      <td>-0.046669</td>\n",
       "      <td>-0.097386</td>\n",
       "      <td>0.248867</td>\n",
       "      <td>0.507259</td>\n",
       "      <td>-0.809193</td>\n",
       "      <td>0.270311</td>\n",
       "      <td>-0.528518</td>\n",
       "      <td>0.616599</td>\n",
       "      <td>-0.166027</td>\n",
       "      <td>1.557793</td>\n",
       "      <td>0.233242</td>\n",
       "      <td>0.708347</td>\n",
       "      <td>0.673513</td>\n",
       "      <td>-0.042416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.119822</td>\n",
       "      <td>0.345573</td>\n",
       "      <td>1.125945</td>\n",
       "      <td>1.004923</td>\n",
       "      <td>-0.129579</td>\n",
       "      <td>-0.089912</td>\n",
       "      <td>-1.146710</td>\n",
       "      <td>1.527909</td>\n",
       "      <td>-0.286878</td>\n",
       "      <td>1.000065</td>\n",
       "      <td>1.579092</td>\n",
       "      <td>-0.546286</td>\n",
       "      <td>3.848888</td>\n",
       "      <td>0.037665</td>\n",
       "      <td>2.118768</td>\n",
       "      <td>-1.193619</td>\n",
       "      <td>1.608002</td>\n",
       "      <td>-1.892853</td>\n",
       "      <td>0.437793</td>\n",
       "      <td>-2.120053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.843470</td>\n",
       "      <td>-1.223616</td>\n",
       "      <td>-1.198011</td>\n",
       "      <td>-0.360786</td>\n",
       "      <td>-0.267575</td>\n",
       "      <td>-0.772806</td>\n",
       "      <td>0.189975</td>\n",
       "      <td>0.581903</td>\n",
       "      <td>-0.260757</td>\n",
       "      <td>-0.856205</td>\n",
       "      <td>-0.876698</td>\n",
       "      <td>-0.471821</td>\n",
       "      <td>-1.624568</td>\n",
       "      <td>-1.715995</td>\n",
       "      <td>-0.833404</td>\n",
       "      <td>-0.219972</td>\n",
       "      <td>-0.499959</td>\n",
       "      <td>1.017576</td>\n",
       "      <td>-2.703195</td>\n",
       "      <td>0.732236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.217474 -1.379587  1.944832 -0.059574 -0.049941  0.669516  1.193189   \n",
       "1 -0.156258 -0.305180 -0.427243  0.658212 -1.824687 -0.196299 -0.528474   \n",
       "2 -0.167395  1.277966  0.867153 -2.152296 -0.333534  0.121870 -0.046669   \n",
       "3  0.119822  0.345573  1.125945  1.004923 -0.129579 -0.089912 -1.146710   \n",
       "4  0.843470 -1.223616 -1.198011 -0.360786 -0.267575 -0.772806  0.189975   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -1.352304  0.084476 -0.242834  0.582384  1.564447  1.181442  1.565118   \n",
       "1  1.907793  0.718183  1.153174 -1.601738  0.149368  3.041237  0.525575   \n",
       "2 -0.097386  0.248867  0.507259 -0.809193  0.270311 -0.528518  0.616599   \n",
       "3  1.527909 -0.286878  1.000065  1.579092 -0.546286  3.848888  0.037665   \n",
       "4  0.581903 -0.260757 -0.856205 -0.876698 -0.471821 -1.624568 -1.715995   \n",
       "\n",
       "         14        15        16        17        18        19  \n",
       "0  1.101566 -0.758229 -1.908754  1.038696  0.662362 -1.855495  \n",
       "1  1.661824  0.566986 -0.136337 -1.539961 -0.535194 -1.642228  \n",
       "2 -0.166027  1.557793  0.233242  0.708347  0.673513 -0.042416  \n",
       "3  2.118768 -1.193619  1.608002 -1.892853  0.437793 -2.120053  \n",
       "4 -0.833404 -0.219972 -0.499959  1.017576 -2.703195  0.732236  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the data.\n",
    "data = pd.DataFrame(X)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  1\n",
       "1  1\n",
       "2  0\n",
       "3  1\n",
       "4  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the data.\n",
    "data_y = pd.DataFrame(y)\n",
    "data_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest Neipours (KNN) from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1,x2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    for i in range(len(x1)):\n",
    "        distance += np.square(x1[i] - x2[i])\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, n_neibours=5):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.n_neibours = n_neibours\n",
    "    \n",
    "    def most_frequent_class(self, neibours_y):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        counts = np.bincount(neibours_y)\n",
    "        return counts.argmax()\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # there is no learning nedded in KNN. Everything happening at the time of prediction.\n",
    "        self.m , self.n = X.shape\n",
    "        self.train_X = X\n",
    "        self.train_y = y\n",
    "\n",
    "    def predict(self, test_X):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # create a empty y_pred array to store the prediction.\n",
    "        y_pred = np.empty((test_X.shape[0], 1))\n",
    "        # iterate over all the test dataset.\n",
    "        for index, test_x in enumerate(test_X):\n",
    "            # Find the euclidean distance between text x sample and all train X values.\n",
    "            # distance_x = [euclidean_distance(test_x, train_x ) for train_x in self.train_X]\n",
    "            # print(\"x_train\", self.train_X) # (10, 20)\n",
    "            # print(\"test x\", test_x) (1,20)\n",
    "            # print(self.train_X - test_x) (10,20)\n",
    "            #  when I row-wise sum it - (10,1) -> then sqr root it thats the distance.\n",
    "            distance = np.sqrt(np.sum((self.train_X - test_x)**2, axis=1))\n",
    "            print(distance)\n",
    "\n",
    "            # Sort the distance and get the first smallest k-neibours's index.\n",
    "            print(np.argsort(distance))\n",
    "            n_neibours_index = np.argsort(distance)[: self.n_neibours]\n",
    "            print(\"n_neig\", n_neibours_index)\n",
    "\n",
    "            # Get the neibours corresponding train_y value.\n",
    "            n_neibours_y = np.array([self.train_y[ind][0] for ind in n_neibours_index ])\n",
    "            \n",
    "            # Get the most frequent class in the n_neibours group as a prediction for that test_x sample.\n",
    "            y_pred[index] = self.most_frequent_class(n_neibours_y)\n",
    "\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, n_neibours):\n",
    "        self.k = n_neibours\n",
    "        self.X = None \n",
    "        self.y = None\n",
    "        self.m = None\n",
    "        self.n = None \n",
    "    \n",
    "\n",
    "    def find_distance(self):\n",
    "        # find the distance bwt text_x and all other train X values.\n",
    "        # text_x = (1,n)\n",
    "        # train_x = (m,n)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def majarity_class(self, k_neighbours):\n",
    "        print(\"k_neighbours\", k_neighbours)\n",
    "        bin_count = np.bincount(k_neighbours)\n",
    "        return int(np.argmax(bin_count))\n",
    "\n",
    "    def train(self, X, y):\n",
    "        # there is no training for this model, just assign variables.\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.m, self.n = X.shape\n",
    "\n",
    "    def predict(self, test_x):\n",
    "        y_pred = []\n",
    "        for t_x in test_x:\n",
    "            # Find the distance bwt the test sample and all the training data.\n",
    "            distance = np.sqrt(np.sum(np.square(t_x - self.X) , axis=1))\n",
    "\n",
    "            # get the k data points with shortest distance.\n",
    "            k_neighbours_index = np.argsort(distance)[: self.k]\n",
    "            print(\"k_neighbours_index\", k_neighbours_index)\n",
    "            k_neighbours = np.array([self.y[ind][0] for ind in k_neighbours_index])\n",
    "\n",
    "            # find the majarity present class.\n",
    "            y_pred.append(self.majarity_class(k_neighbours))\n",
    "        print(y_pred)\n",
    "        return np.array(np.reshape(y_pred, (self.m, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "k_neighbours_index [0 9 2 8 6]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m knn_cla.train(X, y) \n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Predict the values.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m y_pred = \u001b[43mknn_cla\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m#calculate accuracy.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(y, y_pred)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mKNN.predict\u001b[39m\u001b[34m(self, test_x)\u001b[39m\n\u001b[32m     36\u001b[39m k_neighbours_index = np.argsort(distance)[: \u001b[38;5;28mself\u001b[39m.k]\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mk_neighbours_index\u001b[39m\u001b[33m\"\u001b[39m, k_neighbours_index)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m k_neighbours = np.array(\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mind\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk_neighbours_index\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     39\u001b[39m k_neighbours = \u001b[38;5;28mself\u001b[39m.y[k_neighbours_index]\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# find the majarity present class.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     36\u001b[39m k_neighbours_index = np.argsort(distance)[: \u001b[38;5;28mself\u001b[39m.k]\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mk_neighbours_index\u001b[39m\u001b[33m\"\u001b[39m, k_neighbours_index)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m k_neighbours = np.array([\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m k_neighbours_index])\n\u001b[32m     39\u001b[39m k_neighbours = \u001b[38;5;28mself\u001b[39m.y[k_neighbours_index]\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# find the majarity present class.\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "#define the parameters\n",
    "param = {\n",
    "    \"n_neibours\" : 5\n",
    "}\n",
    "print(\"=\"*100)\n",
    "knn_cla = KNN(**param)\n",
    "\n",
    "# Train the model.\n",
    "knn_cla.train(X, y) \n",
    "\n",
    "# Predict the values.\n",
    "y_pred = knn_cla.predict(X)\n",
    "\n",
    "#calculate accuracy.\n",
    "print(y, y_pred)\n",
    "acc = np.sum(y==y_pred)/X.shape[0]\n",
    "print(\"=\"*100)\n",
    "print(\"Accuracy of the prediction is {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN using scikit-learn for comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Number of training data samples-----> 10\n",
      "Number of training features --------> 20\n"
     ]
    }
   ],
   "source": [
    "# data is already defined, going to use the same data for comparision.\n",
    "print(\"=\"*100)\n",
    "print(\"Number of training data samples-----> {}\".format(X.shape[0]))\n",
    "print(\"Number of training features --------> {}\".format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Accuracy of the prediction is 0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pavithradevim/.pyenv/versions/3.11.11/lib/python3.11/site-packages/sklearn/neighbors/_classification.py:239: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "knn_sklearn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_sklearn.fit(X, y)\n",
    "\n",
    "# predict the value\n",
    "y_pred_sklearn = knn_sklearn.predict(X)\n",
    "acc = accuracy_score(y, y_pred_sklearn)\n",
    "print(\"=\"*100)\n",
    "print(\"Accuracy of the prediction is {}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. The accuracy of out model is very much the same as scikit-learn KNN. :)\n",
    "- 2. But our model is little bit slow and so expensive since it is calculating distance with all tarin x for each test x sample. :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Machine Learning models scratch series....\n",
    "you can also check....\n",
    "\n",
    "- 1) Linear Regression         ---> https://www.kaggle.com/ninjaac/linear-regression-from-scratch\n",
    "- 2) Lasso Regression          ---> https://www.kaggle.com/ninjaac/lasso-ridge-regression \n",
    "- 3) Ridge Regression          ---> https://www.kaggle.com/ninjaac/lasso-ridge-regression \n",
    "- 4) ElasticNet Regression     ---> https://www.kaggle.com/ninjaac/elasticnet-regression \n",
    "- 5) Polynomail Regression     ---> https://www.kaggle.com/ninjaac/polynomial-and-polynomialridge-regression \n",
    "- 5) PolynomailRidge Regression---> https://www.kaggle.com/ninjaac/polynomial-and-polynomialridge-regression (Same Notebook you are looking now)\n",
    "- 6) KNN Classifier            ---> (Same Notebook you are looking now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
